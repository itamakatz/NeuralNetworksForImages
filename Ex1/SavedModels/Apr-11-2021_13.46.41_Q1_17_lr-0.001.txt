Net(
  (conv1): Conv2d(3, 4, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(4, 6, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=150, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
  (loss_function): CrossEntropyLoss()
)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 4, 28, 28]             304
         MaxPool2d-2            [-1, 4, 14, 14]               0
            Conv2d-3            [-1, 6, 10, 10]             606
         MaxPool2d-4              [-1, 6, 5, 5]               0
            Linear-5                  [-1, 120]          18,120
            Linear-6                   [-1, 84]          10,164
            Linear-7                   [-1, 10]             850
================================================================
Total params: 30,044
Trainable params: 30,044
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.04
Params size (MB): 0.11
Estimated Total Size (MB): 0.16
----------------------------------------------------------------

Extra info:
Model's state_dict:
conv1.weight 	 torch.Size([4, 3, 5, 5])
conv1.bias 	 torch.Size([4])
conv2.weight 	 torch.Size([6, 4, 5, 5])
conv2.bias 	 torch.Size([6])
fc1.weight 	 torch.Size([120, 150])
fc1.bias 	 torch.Size([120])
fc2.weight 	 torch.Size([84, 120])
fc2.bias 	 torch.Size([84])
fc3.weight 	 torch.Size([10, 84])
fc3.bias 	 torch.Size([10])

Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}]

epoch: 1, train_loss: 1.8920121782231332, train_accuracy: 0.29702, test_loss: 1.5491634369134903, test_accuracy: 0.4239
