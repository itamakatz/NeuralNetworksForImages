Net(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=2048, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=10, bias=True)
  (loss_function): CrossEntropyLoss()
)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 32, 32, 32]             896
            Conv2d-2           [-1, 32, 32, 32]           9,248
         MaxPool2d-3           [-1, 32, 16, 16]               0
            Conv2d-4           [-1, 64, 16, 16]          18,496
            Conv2d-5           [-1, 64, 16, 16]          36,928
         MaxPool2d-6             [-1, 64, 8, 8]               0
            Conv2d-7            [-1, 128, 8, 8]          73,856
            Conv2d-8            [-1, 128, 8, 8]         147,584
         MaxPool2d-9            [-1, 128, 4, 4]               0
           Linear-10                  [-1, 128]         262,272
           Linear-11                   [-1, 10]           1,290
================================================================
Total params: 550,570
Trainable params: 550,570
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.99
Params size (MB): 2.10
Estimated Total Size (MB): 3.10
----------------------------------------------------------------

Extra info:
Model's state_dict:
conv1.weight 	 torch.Size([32, 3, 3, 3])
conv1.bias 	 torch.Size([32])
conv2.weight 	 torch.Size([32, 32, 3, 3])
conv2.bias 	 torch.Size([32])
conv3.weight 	 torch.Size([64, 32, 3, 3])
conv3.bias 	 torch.Size([64])
conv4.weight 	 torch.Size([64, 64, 3, 3])
conv4.bias 	 torch.Size([64])
conv5.weight 	 torch.Size([128, 64, 3, 3])
conv5.bias 	 torch.Size([128])
conv6.weight 	 torch.Size([128, 128, 3, 3])
conv6.bias 	 torch.Size([128])
fc1.weight 	 torch.Size([128, 2048])
fc1.bias 	 torch.Size([128])
fc2.weight 	 torch.Size([10, 128])
fc2.bias 	 torch.Size([10])

Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}]

epoch: 1, train_loss: 2.1067338796281816, train_accuracy: 0.18818, test_loss: 1.6922618679285049, test_accuracy: 0.3604
epoch: 2, train_loss: 1.4154948530083895, train_accuracy: 0.48228, test_loss: 1.187728207024932, test_accuracy: 0.5745
epoch: 3, train_loss: 1.03062479160361, train_accuracy: 0.63298, test_loss: 0.961488351520896, test_accuracy: 0.6681
epoch: 4, train_loss: 0.8004696860277281, train_accuracy: 0.71708, test_loss: 0.7762252847173251, test_accuracy: 0.7311
epoch: 5, train_loss: 0.653046165589816, train_accuracy: 0.77072, test_loss: 0.7339692890102044, test_accuracy: 0.7487
epoch: 6, train_loss: 0.5495687979546027, train_accuracy: 0.8068, test_loss: 0.6882896470401203, test_accuracy: 0.7644
epoch: 7, train_loss: 0.4623946509056386, train_accuracy: 0.83704, test_loss: 0.7703293143092771, test_accuracy: 0.7459
epoch: 8, train_loss: 0.38961128341749324, train_accuracy: 0.86268, test_loss: 0.729006422701181, test_accuracy: 0.7735
epoch: 9, train_loss: 0.3409074625302384, train_accuracy: 0.87932, test_loss: 0.725775258341023, test_accuracy: 0.7846
epoch: 10, train_loss: 0.2966649243872905, train_accuracy: 0.89622, test_loss: 0.7860565946344458, test_accuracy: 0.7663
epoch: 11, train_loss: 0.2635111641663593, train_accuracy: 0.90632, test_loss: 0.8391933076091871, test_accuracy: 0.7702
epoch: 12, train_loss: 0.2541675795294869, train_accuracy: 0.91184, test_loss: 0.8528338849699092, test_accuracy: 0.7717
epoch: 13, train_loss: 0.23236996721313305, train_accuracy: 0.91924, test_loss: 0.8731328231372146, test_accuracy: 0.7762
epoch: 14, train_loss: 0.2244152440087025, train_accuracy: 0.92294, test_loss: 0.968340979707538, test_accuracy: 0.7668
epoch: 15, train_loss: 0.20793462435062168, train_accuracy: 0.929, test_loss: 1.0537131185252864, test_accuracy: 0.7636
epoch: 16, train_loss: 0.2105674126043596, train_accuracy: 0.92868, test_loss: 1.2144007907388894, test_accuracy: 0.7322
epoch: 17, train_loss: 0.2018266902519018, train_accuracy: 0.9317, test_loss: 1.0147031581653334, test_accuracy: 0.7742
epoch: 18, train_loss: 0.19693259672258936, train_accuracy: 0.93422, test_loss: 1.119142438949438, test_accuracy: 0.7668
epoch: 19, train_loss: 0.18887217075951812, train_accuracy: 0.9381, test_loss: 1.2075062407644592, test_accuracy: 0.7605
epoch: 20, train_loss: 0.2031586387866288, train_accuracy: 0.9326, test_loss: 1.099690439772687, test_accuracy: 0.7695
epoch: 21, train_loss: 0.200740513477317, train_accuracy: 0.9349, test_loss: 1.3165305885454575, test_accuracy: 0.7326
epoch: 22, train_loss: 0.20033249713577453, train_accuracy: 0.9352, test_loss: 1.2574550392098431, test_accuracy: 0.7413
epoch: 23, train_loss: 0.19776891567512458, train_accuracy: 0.93654, test_loss: 1.143998046615992, test_accuracy: 0.7623
epoch: 24, train_loss: 0.1955311782951502, train_accuracy: 0.93686, test_loss: 1.2285769774554967, test_accuracy: 0.7532
epoch: 25, train_loss: 0.202519350781957, train_accuracy: 0.9347, test_loss: 1.151296825596259, test_accuracy: 0.753
epoch: 26, train_loss: 0.21864657339894508, train_accuracy: 0.9305, test_loss: 1.1201622518283807, test_accuracy: 0.7541
epoch: 27, train_loss: 0.2090667098503652, train_accuracy: 0.93274, test_loss: 1.2875067388813914, test_accuracy: 0.7542
epoch: 28, train_loss: 0.2211459377619444, train_accuracy: 0.92984, test_loss: 1.1220277305122706, test_accuracy: 0.7552
epoch: 29, train_loss: 0.22871881402901453, train_accuracy: 0.92734, test_loss: 1.1218087079504075, test_accuracy: 0.7607
