Net(
  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1))
  (conv3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1))
  (conv4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
  (loss_function): CrossEntropyLoss()
)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 8, 30, 30]             224
            Conv2d-2            [-1, 8, 28, 28]             584
         MaxPool2d-3            [-1, 8, 14, 14]               0
            Conv2d-4            [-1, 8, 12, 12]             584
            Conv2d-5           [-1, 16, 10, 10]           1,168
         MaxPool2d-6             [-1, 16, 5, 5]               0
            Linear-7                  [-1, 120]          48,120
            Linear-8                   [-1, 84]          10,164
            Linear-9                   [-1, 10]             850
================================================================
Total params: 61,694
Trainable params: 61,694
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.14
Params size (MB): 0.24
Estimated Total Size (MB): 0.39
----------------------------------------------------------------

Extra info:
Model's state_dict:
conv1.weight 	 torch.Size([8, 3, 3, 3])
conv1.bias 	 torch.Size([8])
conv2.weight 	 torch.Size([8, 8, 3, 3])
conv2.bias 	 torch.Size([8])
conv3.weight 	 torch.Size([8, 8, 3, 3])
conv3.bias 	 torch.Size([8])
conv4.weight 	 torch.Size([16, 8, 3, 3])
conv4.bias 	 torch.Size([16])
fc1.weight 	 torch.Size([120, 400])
fc1.bias 	 torch.Size([120])
fc2.weight 	 torch.Size([84, 120])
fc2.bias 	 torch.Size([84])
fc3.weight 	 torch.Size([10, 84])
fc3.bias 	 torch.Size([10])

Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]}]

epoch: 1, train_loss: 1.9746241507816316, train_accuracy: 0.2622, test_loss: 1.6294334815382958, test_accuracy: 0.4032
epoch: 2, train_loss: 1.4745953230512143, train_accuracy: 0.46384, test_loss: 1.4354626586079597, test_accuracy: 0.4839
epoch: 3, train_loss: 1.2807821349611879, train_accuracy: 0.54028, test_loss: 1.3012867498219014, test_accuracy: 0.5333
epoch: 4, train_loss: 1.1474262720660866, train_accuracy: 0.59292, test_loss: 1.1698809351861477, test_accuracy: 0.5877
epoch: 5, train_loss: 1.0564542344169319, train_accuracy: 0.62784, test_loss: 1.0996757422814145, test_accuracy: 0.6224
epoch: 6, train_loss: 1.001576469944436, train_accuracy: 0.64766, test_loss: 1.0500151274178178, test_accuracy: 0.6336
epoch: 7, train_loss: 0.9505130683846399, train_accuracy: 0.66644, test_loss: 1.0645358589452691, test_accuracy: 0.6272
epoch: 8, train_loss: 0.911717492048163, train_accuracy: 0.67888, test_loss: 1.0718627444865183, test_accuracy: 0.6306
epoch: 9, train_loss: 0.8791586727141589, train_accuracy: 0.6914, test_loss: 1.0552694664482027, test_accuracy: 0.6411
epoch: 10, train_loss: 0.8510159849892184, train_accuracy: 0.70144, test_loss: 1.1003159887209535, test_accuracy: 0.6298
epoch: 11, train_loss: 0.831201225779457, train_accuracy: 0.70752, test_loss: 1.1010520234561176, test_accuracy: 0.634
epoch: 12, train_loss: 0.8120413254239606, train_accuracy: 0.71352, test_loss: 1.095672529349057, test_accuracy: 0.6345
epoch: 13, train_loss: 0.7957330485529779, train_accuracy: 0.71654, test_loss: 1.1311481727894672, test_accuracy: 0.6336
epoch: 14, train_loss: 0.7904427178500413, train_accuracy: 0.72152, test_loss: 1.141120642768171, test_accuracy: 0.641
epoch: 15, train_loss: 0.7694992681888864, train_accuracy: 0.72642, test_loss: 1.1327702327313949, test_accuracy: 0.631
epoch: 16, train_loss: 0.7579748240140302, train_accuracy: 0.73232, test_loss: 1.1600769195093992, test_accuracy: 0.6289
epoch: 17, train_loss: 0.7549364178976248, train_accuracy: 0.73432, test_loss: 1.1353262388096423, test_accuracy: 0.6353
epoch: 18, train_loss: 0.7484221553985868, train_accuracy: 0.73618, test_loss: 1.1366707329850876, test_accuracy: 0.6329
epoch: 19, train_loss: 0.7392140307377099, train_accuracy: 0.74054, test_loss: 1.1652866188208557, test_accuracy: 0.6358
epoch: 20, train_loss: 0.7277570188429812, train_accuracy: 0.7434, test_loss: 1.1996986603024038, test_accuracy: 0.6355
epoch: 21, train_loss: 0.7216471466632746, train_accuracy: 0.7452, test_loss: 1.2148819835232338, test_accuracy: 0.6193
epoch: 22, train_loss: 0.722969509180612, train_accuracy: 0.74544, test_loss: 1.1409589532904327, test_accuracy: 0.6269
epoch: 23, train_loss: 0.7133249408324644, train_accuracy: 0.74986, test_loss: 1.2312027817894253, test_accuracy: 0.6317
epoch: 24, train_loss: 0.7078189403759446, train_accuracy: 0.75162, test_loss: 1.2641318319732526, test_accuracy: 0.6286
epoch: 25, train_loss: 0.7086598727091477, train_accuracy: 0.75278, test_loss: 1.1928087553004727, test_accuracy: 0.6349
epoch: 26, train_loss: 0.7001616439635365, train_accuracy: 0.75586, test_loss: 1.30405248264361, test_accuracy: 0.6196
epoch: 27, train_loss: 0.7048022917674067, train_accuracy: 0.75316, test_loss: 1.2754529241833137, test_accuracy: 0.6129
epoch: 28, train_loss: 0.7070782056753215, train_accuracy: 0.75242, test_loss: 1.251544906918121, test_accuracy: 0.6198
epoch: 29, train_loss: 0.7002235488608118, train_accuracy: 0.7547, test_loss: 1.2550641525678365, test_accuracy: 0.6246
epoch: 30, train_loss: 0.704172591825127, train_accuracy: 0.75418, test_loss: 1.2647221077897481, test_accuracy: 0.6256
epoch: 31, train_loss: 0.6991121737805556, train_accuracy: 0.7566, test_loss: 1.2980015779299043, test_accuracy: 0.6219
epoch: 32, train_loss: 0.6992209044380842, train_accuracy: 0.7572, test_loss: 1.306166243846342, test_accuracy: 0.6221
epoch: 33, train_loss: 0.693289549100912, train_accuracy: 0.75854, test_loss: 1.32284447862043, test_accuracy: 0.6262
epoch: 34, train_loss: 0.6897884616047455, train_accuracy: 0.75834, test_loss: 1.3821124034668058, test_accuracy: 0.6178
epoch: 35, train_loss: 0.701601193428295, train_accuracy: 0.7577, test_loss: 1.3487905507219315, test_accuracy: 0.6119
epoch: 36, train_loss: 0.6925024406841924, train_accuracy: 0.75982, test_loss: 1.295651261883456, test_accuracy: 0.6258
epoch: 37, train_loss: 0.703760800072844, train_accuracy: 0.75752, test_loss: 1.295935682838643, test_accuracy: 0.6208
epoch: 38, train_loss: 0.6951295917006611, train_accuracy: 0.75784, test_loss: 1.3380557042922359, test_accuracy: 0.6117
epoch: 39, train_loss: 0.699458407975238, train_accuracy: 0.75974, test_loss: 1.330232919271753, test_accuracy: 0.6059
epoch: 40, train_loss: 0.6958840405048634, train_accuracy: 0.75866, test_loss: 1.3504076050675187, test_accuracy: 0.6078
