Net(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 8, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=200, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
  (loss_function): CrossEntropyLoss()
)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 6, 28, 28]             456
         MaxPool2d-2            [-1, 6, 14, 14]               0
            Conv2d-3            [-1, 8, 10, 10]           1,208
         MaxPool2d-4              [-1, 8, 5, 5]               0
            Linear-5                  [-1, 120]          24,120
            Linear-6                   [-1, 84]          10,164
            Linear-7                   [-1, 10]             850
================================================================
Total params: 36,798
Trainable params: 36,798
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.05
Params size (MB): 0.14
Estimated Total Size (MB): 0.21
----------------------------------------------------------------

Extra info:
Model's state_dict:
conv1.weight 	 torch.Size([6, 3, 5, 5])
conv1.bias 	 torch.Size([6])
conv2.weight 	 torch.Size([8, 6, 5, 5])
conv2.bias 	 torch.Size([8])
fc1.weight 	 torch.Size([120, 200])
fc1.bias 	 torch.Size([120])
fc2.weight 	 torch.Size([84, 120])
fc2.bias 	 torch.Size([84])
fc3.weight 	 torch.Size([10, 84])
fc3.bias 	 torch.Size([10])

Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}]

epoch: 1, train_loss: 1.7826449976587295, train_accuracy: 0.34012, test_loss: 1.5176934094190597, test_accuracy: 0.4472
epoch: 2, train_loss: 1.4504778655672073, train_accuracy: 0.47626, test_loss: 1.3607429145097734, test_accuracy: 0.5162
epoch: 3, train_loss: 1.3495925235974788, train_accuracy: 0.51644, test_loss: 1.329868487945199, test_accuracy: 0.5269
epoch: 4, train_loss: 1.2782298168176414, train_accuracy: 0.54318, test_loss: 1.250782237625122, test_accuracy: 0.5552
epoch: 5, train_loss: 1.2223396948993206, train_accuracy: 0.5654, test_loss: 1.2967459036141633, test_accuracy: 0.5451
epoch: 6, train_loss: 1.1769860642878711, train_accuracy: 0.5818, test_loss: 1.2370738951593638, test_accuracy: 0.571
epoch: 7, train_loss: 1.144686957014799, train_accuracy: 0.59614, test_loss: 1.2589259495168925, test_accuracy: 0.561
epoch: 8, train_loss: 1.1104177612877637, train_accuracy: 0.60584, test_loss: 1.224899082288146, test_accuracy: 0.5722
epoch: 9, train_loss: 1.088705532579124, train_accuracy: 0.61392, test_loss: 1.2201799726486207, test_accuracy: 0.569
epoch: 10, train_loss: 1.060396018473953, train_accuracy: 0.62428, test_loss: 1.2415419334162026, test_accuracy: 0.578
epoch: 11, train_loss: 1.0407679528319091, train_accuracy: 0.63258, test_loss: 1.2616657845184207, test_accuracy: 0.5692
epoch: 12, train_loss: 1.0227838151662796, train_accuracy: 0.63674, test_loss: 1.2275913017041982, test_accuracy: 0.5816
epoch: 13, train_loss: 1.0065452482251172, train_accuracy: 0.6433, test_loss: 1.366456479024142, test_accuracy: 0.5407
epoch: 14, train_loss: 0.9933598861273983, train_accuracy: 0.6472, test_loss: 1.2333882585093379, test_accuracy: 0.5808
epoch: 15, train_loss: 0.974883739377223, train_accuracy: 0.65478, test_loss: 1.288659536838904, test_accuracy: 0.5787
epoch: 16, train_loss: 0.9656333183135092, train_accuracy: 0.65934, test_loss: 1.3122451148830354, test_accuracy: 0.5764
epoch: 17, train_loss: 0.9591654100679233, train_accuracy: 0.66148, test_loss: 1.2937749927256257, test_accuracy: 0.5777
epoch: 18, train_loss: 0.947712414651066, train_accuracy: 0.66458, test_loss: 1.2962852485597134, test_accuracy: 0.5785
epoch: 19, train_loss: 0.9399073255405529, train_accuracy: 0.66764, test_loss: 1.3117555818967288, test_accuracy: 0.575
epoch: 20, train_loss: 0.9314741064893827, train_accuracy: 0.67024, test_loss: 1.2948313746242783, test_accuracy: 0.581
epoch: 21, train_loss: 0.9288258927512448, train_accuracy: 0.67066, test_loss: 1.3018997408296913, test_accuracy: 0.5752
epoch: 22, train_loss: 0.925736850670008, train_accuracy: 0.6707, test_loss: 1.320700779933855, test_accuracy: 0.5751
epoch: 23, train_loss: 0.9130349336297438, train_accuracy: 0.67606, test_loss: 1.3597702852919697, test_accuracy: 0.5684
epoch: 24, train_loss: 0.9149282255841232, train_accuracy: 0.67666, test_loss: 1.3329786989380605, test_accuracy: 0.5671
epoch: 25, train_loss: 0.9026328188526491, train_accuracy: 0.67972, test_loss: 1.4694235844848211, test_accuracy: 0.5548
epoch: 26, train_loss: 0.8957567252476281, train_accuracy: 0.68318, test_loss: 1.4136566114575602, test_accuracy: 0.5652
epoch: 27, train_loss: 0.8974525456534017, train_accuracy: 0.68426, test_loss: 1.3751716800175606, test_accuracy: 0.5748
epoch: 28, train_loss: 0.8920738411913254, train_accuracy: 0.6861, test_loss: 1.3517294634475605, test_accuracy: 0.5785
epoch: 29, train_loss: 0.8853126865858585, train_accuracy: 0.68582, test_loss: 1.3691488935139031, test_accuracy: 0.572
epoch: 30, train_loss: 0.8791864465433127, train_accuracy: 0.68784, test_loss: 1.411893347364664, test_accuracy: 0.5712
epoch: 31, train_loss: 0.8819173227208387, train_accuracy: 0.68836, test_loss: 1.4622979259941726, test_accuracy: 0.5629
epoch: 32, train_loss: 0.884017625795581, train_accuracy: 0.68902, test_loss: 1.4348577426886187, test_accuracy: 0.5721
epoch: 33, train_loss: 0.8760991803048831, train_accuracy: 0.68978, test_loss: 1.4715183188237715, test_accuracy: 0.5572
