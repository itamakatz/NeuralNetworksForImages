Net(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 10, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=250, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
  (loss_function): CrossEntropyLoss()
)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 6, 28, 28]             456
         MaxPool2d-2            [-1, 6, 14, 14]               0
            Conv2d-3           [-1, 10, 10, 10]           1,510
         MaxPool2d-4             [-1, 10, 5, 5]               0
            Linear-5                  [-1, 120]          30,120
            Linear-6                   [-1, 84]          10,164
            Linear-7                   [-1, 10]             850
================================================================
Total params: 43,100
Trainable params: 43,100
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.06
Params size (MB): 0.16
Estimated Total Size (MB): 0.23
----------------------------------------------------------------

Extra info:
Model's state_dict:
conv1.weight 	 torch.Size([6, 3, 5, 5])
conv1.bias 	 torch.Size([6])
conv2.weight 	 torch.Size([10, 6, 5, 5])
conv2.bias 	 torch.Size([10])
fc1.weight 	 torch.Size([120, 250])
fc1.bias 	 torch.Size([120])
fc2.weight 	 torch.Size([84, 120])
fc2.bias 	 torch.Size([84])
fc3.weight 	 torch.Size([10, 84])
fc3.bias 	 torch.Size([10])

Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}]

epoch: 1, train_loss: 1.7777202040076256, train_accuracy: 0.34246, test_loss: 1.5052579969406128, test_accuracy: 0.4546
epoch: 2, train_loss: 1.4189707091498376, train_accuracy: 0.48494, test_loss: 1.3250207026720047, test_accuracy: 0.5245
epoch: 3, train_loss: 1.2916877320092917, train_accuracy: 0.53702, test_loss: 1.2531637064933776, test_accuracy: 0.5554
epoch: 4, train_loss: 1.2083806872358918, train_accuracy: 0.57108, test_loss: 1.2134391539543867, test_accuracy: 0.5648
epoch: 5, train_loss: 1.1448565249018372, train_accuracy: 0.59434, test_loss: 1.207175373184681, test_accuracy: 0.576
epoch: 6, train_loss: 1.100221577140242, train_accuracy: 0.61072, test_loss: 1.1508879881300031, test_accuracy: 0.5985
epoch: 7, train_loss: 1.0580148668886722, train_accuracy: 0.62876, test_loss: 1.1864663421541453, test_accuracy: 0.5824
epoch: 8, train_loss: 1.028239971181266, train_accuracy: 0.63742, test_loss: 1.1802112178623676, test_accuracy: 0.5974
epoch: 9, train_loss: 0.9987803598092496, train_accuracy: 0.64776, test_loss: 1.1499540701165796, test_accuracy: 0.5994
epoch: 10, train_loss: 0.9709048771700636, train_accuracy: 0.65504, test_loss: 1.1502268736444414, test_accuracy: 0.6059
epoch: 11, train_loss: 0.9513347855070978, train_accuracy: 0.66496, test_loss: 1.167741551255621, test_accuracy: 0.6094
epoch: 12, train_loss: 0.9296222164197545, train_accuracy: 0.67084, test_loss: 1.2039114749770612, test_accuracy: 0.5872
epoch: 13, train_loss: 0.9133893492570891, train_accuracy: 0.67606, test_loss: 1.1696435269236565, test_accuracy: 0.6072
epoch: 14, train_loss: 0.9000470395734533, train_accuracy: 0.68066, test_loss: 1.1947194118976594, test_accuracy: 0.6043
epoch: 15, train_loss: 0.8817152081662882, train_accuracy: 0.68632, test_loss: 1.217237950566737, test_accuracy: 0.6036
epoch: 16, train_loss: 0.8700265367352776, train_accuracy: 0.6918, test_loss: 1.1934721890155227, test_accuracy: 0.6089
epoch: 17, train_loss: 0.8604766971777845, train_accuracy: 0.69508, test_loss: 1.2606425926519558, test_accuracy: 0.5877
epoch: 18, train_loss: 0.847096081935726, train_accuracy: 0.69862, test_loss: 1.2255816043396712, test_accuracy: 0.5987
epoch: 19, train_loss: 0.8413790310954768, train_accuracy: 0.7034, test_loss: 1.2996289725774899, test_accuracy: 0.588
epoch: 20, train_loss: 0.8313655884626787, train_accuracy: 0.70434, test_loss: 1.2722765852677869, test_accuracy: 0.5941
epoch: 21, train_loss: 0.8183177614221582, train_accuracy: 0.70858, test_loss: 1.3499209348753094, test_accuracy: 0.5778
epoch: 22, train_loss: 0.81615310901633, train_accuracy: 0.71086, test_loss: 1.3241494158406277, test_accuracy: 0.5842
epoch: 23, train_loss: 0.8122122318070638, train_accuracy: 0.71194, test_loss: 1.330834945446253, test_accuracy: 0.584
epoch: 24, train_loss: 0.8046084800264728, train_accuracy: 0.71436, test_loss: 1.3620341310041024, test_accuracy: 0.5824
epoch: 25, train_loss: 0.7942201821755734, train_accuracy: 0.71982, test_loss: 1.3238652362041174, test_accuracy: 0.5828
epoch: 26, train_loss: 0.7898268114662578, train_accuracy: 0.72002, test_loss: 1.3632059676709585, test_accuracy: 0.5966
epoch: 27, train_loss: 0.7868388258568646, train_accuracy: 0.72164, test_loss: 1.3347286992462353, test_accuracy: 0.594
epoch: 28, train_loss: 0.7867862348512048, train_accuracy: 0.72222, test_loss: 1.360228605966596, test_accuracy: 0.5894
epoch: 29, train_loss: 0.7769843776229722, train_accuracy: 0.72442, test_loss: 1.3574104627980386, test_accuracy: 0.5937
epoch: 30, train_loss: 0.7767427800451457, train_accuracy: 0.72424, test_loss: 1.4237387878891081, test_accuracy: 0.5857
epoch: 31, train_loss: 0.7708752344019943, train_accuracy: 0.72896, test_loss: 1.4159654614503727, test_accuracy: 0.5849
epoch: 32, train_loss: 0.7680183621307265, train_accuracy: 0.72968, test_loss: 1.4494344241258688, test_accuracy: 0.5872
epoch: 33, train_loss: 0.7683181718646822, train_accuracy: 0.7308, test_loss: 1.4850900642887486, test_accuracy: 0.5846
epoch: 34, train_loss: 0.7705547917884065, train_accuracy: 0.72772, test_loss: 1.5639472280443414, test_accuracy: 0.5593
