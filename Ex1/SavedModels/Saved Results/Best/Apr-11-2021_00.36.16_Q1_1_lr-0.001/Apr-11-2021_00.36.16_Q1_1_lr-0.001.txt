Net(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
  (loss_function): CrossEntropyLoss()
)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 6, 28, 28]             456
         MaxPool2d-2            [-1, 6, 14, 14]               0
            Conv2d-3           [-1, 16, 10, 10]           2,416
         MaxPool2d-4             [-1, 16, 5, 5]               0
            Linear-5                  [-1, 120]          48,120
            Linear-6                   [-1, 84]          10,164
            Linear-7                   [-1, 10]             850
================================================================
Total params: 62,006
Trainable params: 62,006
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 0.06
Params size (MB): 0.24
Estimated Total Size (MB): 0.31
----------------------------------------------------------------

Extra info:
Model's state_dict:
conv1.weight 	 torch.Size([6, 3, 5, 5])
conv1.bias 	 torch.Size([6])
conv2.weight 	 torch.Size([16, 6, 5, 5])
conv2.bias 	 torch.Size([16])
fc1.weight 	 torch.Size([120, 400])
fc1.bias 	 torch.Size([120])
fc2.weight 	 torch.Size([84, 120])
fc2.bias 	 torch.Size([84])
fc3.weight 	 torch.Size([10, 84])
fc3.bias 	 torch.Size([10])

Optimizer's state_dict:
state 	 {}
param_groups 	 [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}]

epoch: 1, train_loss: 1.6954962700855731, train_accuracy: 0.37836, test_loss: 1.3855471977293492, test_accuracy: 0.5107
epoch: 2, train_loss: 1.3076997995984554, train_accuracy: 0.52932, test_loss: 1.2378039737150073, test_accuracy: 0.5516
epoch: 3, train_loss: 1.1685763024297358, train_accuracy: 0.58688, test_loss: 1.135747247326374, test_accuracy: 0.5985
epoch: 4, train_loss: 1.0790918857447058, train_accuracy: 0.61772, test_loss: 1.1447288924574852, test_accuracy: 0.6023
epoch: 5, train_loss: 1.0152995152266695, train_accuracy: 0.64284, test_loss: 1.1252548599660397, test_accuracy: 0.6134
epoch: 6, train_loss: 0.9594138526883721, train_accuracy: 0.66178, test_loss: 1.0909461499094963, test_accuracy: 0.6238
epoch: 7, train_loss: 0.9214025385428779, train_accuracy: 0.67516, test_loss: 1.0794321257926525, test_accuracy: 0.6331
epoch: 8, train_loss: 0.881653684078604, train_accuracy: 0.6892, test_loss: 1.1084897484399379, test_accuracy: 0.6223
epoch: 9, train_loss: 0.8516748484575888, train_accuracy: 0.70192, test_loss: 1.0910420591283123, test_accuracy: 0.6382
epoch: 10, train_loss: 0.8219194443787617, train_accuracy: 0.70782, test_loss: 1.1640575753579614, test_accuracy: 0.6228
epoch: 11, train_loss: 0.7936738309298316, train_accuracy: 0.71814, test_loss: 1.1674654871459118, test_accuracy: 0.6164
epoch: 12, train_loss: 0.7770517753796093, train_accuracy: 0.72536, test_loss: 1.141257539252937, test_accuracy: 0.6289
epoch: 13, train_loss: 0.758376995698018, train_accuracy: 0.73048, test_loss: 1.1341527688806876, test_accuracy: 0.6383
epoch: 14, train_loss: 0.7373619628909487, train_accuracy: 0.73874, test_loss: 1.2480584358297928, test_accuracy: 0.6176
epoch: 15, train_loss: 0.7266804319747433, train_accuracy: 0.74144, test_loss: 1.3169733100160026, test_accuracy: 0.6031
epoch: 16, train_loss: 0.708666877127256, train_accuracy: 0.74604, test_loss: 1.242640320280753, test_accuracy: 0.6229
epoch: 17, train_loss: 0.6938008259081643, train_accuracy: 0.75076, test_loss: 1.2814749663415015, test_accuracy: 0.6116
epoch: 18, train_loss: 0.6836510841612824, train_accuracy: 0.75636, test_loss: 1.2645716422419995, test_accuracy: 0.6182
epoch: 19, train_loss: 0.670846242660499, train_accuracy: 0.762, test_loss: 1.3149241255778354, test_accuracy: 0.6212
epoch: 20, train_loss: 0.6633455390880377, train_accuracy: 0.76366, test_loss: 1.3250723756927705, test_accuracy: 0.6168
epoch: 21, train_loss: 0.6546288816574651, train_accuracy: 0.76702, test_loss: 1.3834288905926515, test_accuracy: 0.6093
epoch: 22, train_loss: 0.6500904738436517, train_accuracy: 0.77028, test_loss: 1.3809322921427898, test_accuracy: 0.6118
epoch: 23, train_loss: 0.6354487696693747, train_accuracy: 0.7762, test_loss: 1.439421008875966, test_accuracy: 0.6171
epoch: 24, train_loss: 0.6316141038917004, train_accuracy: 0.77968, test_loss: 1.4405545875546726, test_accuracy: 0.6044
epoch: 25, train_loss: 0.6355133402079148, train_accuracy: 0.77586, test_loss: 1.397712739347294, test_accuracy: 0.6042
epoch: 26, train_loss: 0.6219926777080761, train_accuracy: 0.78288, test_loss: 1.5543965158192083, test_accuracy: 0.6035
epoch: 27, train_loss: 0.6326849751709748, train_accuracy: 0.77844, test_loss: 1.476089488833875, test_accuracy: 0.6066
epoch: 28, train_loss: 0.6153751355880442, train_accuracy: 0.7859, test_loss: 1.5025989702308624, test_accuracy: 0.6054
epoch: 29, train_loss: 0.6082037829285639, train_accuracy: 0.7889, test_loss: 1.5645985154286228, test_accuracy: 0.6028
epoch: 30, train_loss: 0.6065423556608968, train_accuracy: 0.78878, test_loss: 1.6203462601175662, test_accuracy: 0.6009
epoch: 31, train_loss: 0.6129147156021358, train_accuracy: 0.78898, test_loss: 1.6320158857388, test_accuracy: 0.5974
epoch: 32, train_loss: 0.6185315446990146, train_accuracy: 0.788, test_loss: 1.7817827186630981, test_accuracy: 0.5855
epoch: 33, train_loss: 0.6137518115358179, train_accuracy: 0.78828, test_loss: 1.7156631001883644, test_accuracy: 0.5964
epoch: 34, train_loss: 0.6090813589034609, train_accuracy: 0.79232, test_loss: 1.7838032850326155, test_accuracy: 0.5926
epoch: 35, train_loss: 0.6138552284812668, train_accuracy: 0.79162, test_loss: 1.8864488985037344, test_accuracy: 0.5708
epoch: 36, train_loss: 0.6104696790698971, train_accuracy: 0.79248, test_loss: 1.7360117551038023, test_accuracy: 0.5873
epoch: 37, train_loss: 0.5988633262994033, train_accuracy: 0.79246, test_loss: 1.76805555267947, test_accuracy: 0.5982
epoch: 38, train_loss: 0.6046303391113828, train_accuracy: 0.79276, test_loss: 1.7964487285269832, test_accuracy: 0.5981
epoch: 39, train_loss: 0.6067124162562327, train_accuracy: 0.79556, test_loss: 1.6825597149205809, test_accuracy: 0.5926
epoch: 40, train_loss: 0.6038959947329232, train_accuracy: 0.79558, test_loss: 1.7354726878591649, test_accuracy: 0.5978
epoch: 41, train_loss: 0.59732767323842, train_accuracy: 0.7979, test_loss: 1.6662099694477737, test_accuracy: 0.5894
epoch: 42, train_loss: 0.6017616962870012, train_accuracy: 0.79646, test_loss: 1.805992499381835, test_accuracy: 0.5967
epoch: 43, train_loss: 0.6057670062032994, train_accuracy: 0.79594, test_loss: 1.7943621383037942, test_accuracy: 0.5914
epoch: 44, train_loss: 0.6065256973106276, train_accuracy: 0.79514, test_loss: 1.8345438734190473, test_accuracy: 0.5872
epoch: 45, train_loss: 0.6126405618072883, train_accuracy: 0.79404, test_loss: 1.8124380773460484, test_accuracy: 0.5796
epoch: 46, train_loss: 0.597566355229338, train_accuracy: 0.79984, test_loss: 1.9421853325909513, test_accuracy: 0.5768
epoch: 47, train_loss: 0.5986418713512213, train_accuracy: 0.79944, test_loss: 1.9229036582468384, test_accuracy: 0.5864
epoch: 48, train_loss: 0.5980598760001732, train_accuracy: 0.79928, test_loss: 1.842864655870146, test_accuracy: 0.5716
epoch: 49, train_loss: 0.6005092501187503, train_accuracy: 0.80274, test_loss: 1.8537951329346218, test_accuracy: 0.5814
epoch: 50, train_loss: 0.6149643652593366, train_accuracy: 0.79572, test_loss: 1.987032890095783, test_accuracy: 0.59

Accuracy of plane : 62 %
Accuracy of   car : 69 %
Accuracy of  bird : 51 %
Accuracy of   cat : 43 %
Accuracy of  deer : 45 %
Accuracy of   dog : 44 %
Accuracy of  frog : 70 %
Accuracy of horse : 63 %
Accuracy of  ship : 74 %
Accuracy of truck : 64 %
